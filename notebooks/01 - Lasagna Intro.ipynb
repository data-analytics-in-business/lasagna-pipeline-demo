{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64183170",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Let's load and explore the example dataset we are going to use in this practical session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf09135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "URL = 'https://github.com/data-analytics-in-business/lasagna-pipeline-demo/raw/main/data/sample_lasagna.csv'\n",
    "df = pd.read_csv(URL)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ff6b28",
   "metadata": {},
   "source": [
    "Let's specify our attribute/predictor variables $X$ and the target variable $y$ that we wish to predict.\n",
    "\n",
    "**Note**: To create $X$, we drop the target variable column and the columns containing the subject ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ec6300",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Have Tried']\n",
    "X = df.drop(columns=['Person','Have Tried'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca4d9ec",
   "metadata": {},
   "source": [
    "# Mixed Types\n",
    "Our input matrix $X$ contains columns of different data types, which would need to be processed in different ways depending on the the data type in each column. Let's first look at the data types in $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3a562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f35e8",
   "metadata": {},
   "source": [
    "We can easily split our input matrix $X$ into numeric columns/features and categorical columns/features. Let's do this now, and look at each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9894aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"Age\", \"Weight\",\"Income\",\"Car Value\",\"CC Debt\",\"Mall Trips\"]\n",
    "categorical_features = [\"Pay Type\",\"Gender\",\"Live Alone\",\"Dwell Type\",\"Nbhd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a320a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = X[numeric_features]\n",
    "X_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa817ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = X[categorical_features]\n",
    "X_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e3cc30",
   "metadata": {},
   "source": [
    "# Processing mixed types\n",
    "Once we've split our input matrix $X$ into numeric and categorical features, we can process each split in a way that is suited to the data type.\n",
    "\n",
    "For example, we can use a `OneHotEncoder` to process the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa2b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "hot_encoder = OneHotEncoder(drop='first', handle_unknown=\"ignore\", sparse=False)\n",
    "hot_encoder.fit(X_cat)\n",
    "X_cat_onehot = pd.DataFrame(hot_encoder.transform(X_cat), \n",
    "                                  columns=hot_encoder.get_feature_names_out(X_cat.columns))\n",
    "X_cat_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfae8fb",
   "metadata": {},
   "source": [
    "For the numeric features, we could process them using a `MinMaxScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ba905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax_scaler = MinMaxScaler()\n",
    "X_num_scaled = pd.DataFrame(minmax_scaler.fit_transform(X_num), columns=X_num.columns)\n",
    "X_num_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3246a1fd",
   "metadata": {},
   "source": [
    "Finally we would need to combine the processed numeric and processed categorical features back into the one processed feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bc8f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = pd.concat([X_num_scaled, X_cat_onehot], axis=1)\n",
    "X_train_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c093175c",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Re-run the above data processing steps using an input matrix $X$ with only columns `Age`, `Weight`, `Income`, `Pay Type`, and `Gender`; and using a `StandardScaler` to process the numeric variables. More precisely:\n",
    "1. Specify the numeric and categorical features and split $X$\n",
    "2. Process categorical features using OneHotEncoder\n",
    "3. Process numeric features using StandardScaler\n",
    "4. Combine results into one processed feature matrix and check it using `head`\n",
    "\n",
    "Below, there is some code to get you started and steps in the comments to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8071d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "y = df['Have Tried']\n",
    "X = df[['Age', 'Weight', 'Income', 'Pay Type', 'Gender']]\n",
    "\n",
    "# (SOLUTION)\n",
    "# Step 1: Specify numeric and categorical features and split X\n",
    "numeric_features = [\"Age\", \"Weight\",\"Income\"]\n",
    "categorical_features = [\"Pay Type\",\"Gender\"]\n",
    "X_num = X[numeric_features]\n",
    "X_cat = X[categorical_features]\n",
    "\n",
    "# Step 2: Process categorical features using OneHotEncoder\n",
    "hot_encoder = OneHotEncoder(drop='first', handle_unknown=\"ignore\", sparse=False)\n",
    "hot_encoder.fit(X_cat)\n",
    "X_cat_onehot = pd.DataFrame(hot_encoder.transform(X_cat), \n",
    "                                  columns=hot_encoder.get_feature_names_out(X_cat.columns))\n",
    "\n",
    "# Step 3: Process numeric features using StandardScaler\n",
    "standard_scaler = StandardScaler()\n",
    "X_num_scaled = pd.DataFrame(standard_scaler.fit_transform(X_num), columns=X_num.columns)\n",
    "\n",
    "# Step 4: Combine results into one processed feature matrix and check it using `head`\n",
    "X_train_preprocessed = pd.concat([X_num_scaled, X_cat_onehot], axis=1)\n",
    "X_train_preprocessed.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
