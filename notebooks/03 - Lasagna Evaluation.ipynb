{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab25c3cc",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this notebook, we are going to optimise the model to perform well on new (unseen) data.\n",
    "\n",
    "Let's load in our data and import all the tools we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b05d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "URL = 'https://github.com/data-analytics-in-business/lasagna-pipeline-demo/raw/main/data/sample_lasagna.csv'\n",
    "df = pd.read_csv(URL)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c5520a",
   "metadata": {},
   "source": [
    "# Training and Testing\n",
    "Let's specify our input $X$ and output $y$ variables, but let's also split them both into a set of samples we will use for training our model and a set of samples we will use for testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15bc64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Have Tried']\n",
    "X = df.drop(columns=['Person','Have Tried'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed0a515",
   "metadata": {},
   "source": [
    "Given training and tesing data, we can create a classification pipeline like before, but this time we will train it on the training data and test it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d914ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"Age\", \"Weight\",\"Income\",\"Car Value\",\"CC Debt\",\"Mall Trips\"]\n",
    "categorical_features = [\"Pay Type\",\"Gender\",\"Live Alone\",\"Dwell Type\",\"Nbhd\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", MinMaxScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(drop='first', handle_unknown=\"ignore\", sparse=False), categorical_features),\n",
    "    ],\n",
    ")\n",
    "\n",
    "clf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "clf_pipeline.fit(X_train, y_train)\n",
    " \n",
    "print('Training set score: ' + str(clf_pipeline.score(X_train,y_train)))\n",
    "print('Test set score: ' + str(clf_pipeline.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eddfef",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "We can use the idea of \"training and testing\" to optimise our model based on an estimate of its performance on unseen data.\n",
    "\n",
    "To do this, we define a grid of parameters that we wish to search over. \n",
    "\n",
    "For this example, we will try different preprocessors for the numeric variables, and we will try different classifiers for the classifer \"head\" of our pipeline.\n",
    "\n",
    "Run the code below to search over the parameter grid and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a736d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'preprocessor__num' : [StandardScaler(), MinMaxScaler(), Normalizer()],\n",
    "    'classifier' : [LogisticRegression(), DecisionTreeClassifier(), GaussianNB()]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(clf_pipeline, param_grid).fit(X_train, y_train)\n",
    " \n",
    "df_results = pd.DataFrame(grid.cv_results_)\n",
    "df_results[['param_classifier','param_preprocessor__num','mean_test_score','rank_test_score']].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa30c20",
   "metadata": {},
   "source": [
    "**Question**: Which classification pipeline do you think will perform best on the unseen data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee86c6d5",
   "metadata": {},
   "source": [
    "# Exercise (Advanced)\n",
    "Explore other [supervised learning](https://scikit-learn.org/stable/supervised_learning.html) classification methods and [preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html) methods, and explore the parameters within those methods, to find the best `mean_test_score` you can find using the `sample_lasagna.csv` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ebe469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (SOLUTION)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
